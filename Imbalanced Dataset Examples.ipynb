{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff1b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fa752",
   "metadata": {},
   "source": [
    "# Imbalanced Dataset Experiments\n",
    "\n",
    "This is a quick and simple demonstration of the type of error which can result from improper use of resampling to balance a dataset before training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d0338",
   "metadata": {},
   "source": [
    "We use a simple toy dataset using scikit-learn's \"make_classification\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32676a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.524584</td>\n",
       "      <td>0.412494</td>\n",
       "      <td>-1.802713</td>\n",
       "      <td>-0.075889</td>\n",
       "      <td>0.744249</td>\n",
       "      <td>-0.555693</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>-2.902355</td>\n",
       "      <td>-1.032001</td>\n",
       "      <td>0.620666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.223714</td>\n",
       "      <td>0.353656</td>\n",
       "      <td>0.433975</td>\n",
       "      <td>-1.692863</td>\n",
       "      <td>1.798698</td>\n",
       "      <td>-0.493160</td>\n",
       "      <td>0.735316</td>\n",
       "      <td>-2.147366</td>\n",
       "      <td>0.918143</td>\n",
       "      <td>-0.925999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.375770</td>\n",
       "      <td>0.091193</td>\n",
       "      <td>-1.311360</td>\n",
       "      <td>-0.922734</td>\n",
       "      <td>-1.721759</td>\n",
       "      <td>2.272621</td>\n",
       "      <td>0.543799</td>\n",
       "      <td>3.121716</td>\n",
       "      <td>-1.228138</td>\n",
       "      <td>-1.326703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040756</td>\n",
       "      <td>0.818655</td>\n",
       "      <td>1.231301</td>\n",
       "      <td>1.584360</td>\n",
       "      <td>-2.103652</td>\n",
       "      <td>0.939735</td>\n",
       "      <td>-0.770357</td>\n",
       "      <td>1.072464</td>\n",
       "      <td>-0.521160</td>\n",
       "      <td>1.035603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.716362</td>\n",
       "      <td>0.052499</td>\n",
       "      <td>-0.947138</td>\n",
       "      <td>1.301603</td>\n",
       "      <td>-0.710176</td>\n",
       "      <td>-0.206302</td>\n",
       "      <td>0.100330</td>\n",
       "      <td>-0.332693</td>\n",
       "      <td>-3.112213</td>\n",
       "      <td>-0.955480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  2.524584  0.412494 -1.802713 -0.075889  0.744249 -0.555693  0.179100   \n",
       "1  1.223714  0.353656  0.433975 -1.692863  1.798698 -0.493160  0.735316   \n",
       "2 -2.375770  0.091193 -1.311360 -0.922734 -1.721759  2.272621  0.543799   \n",
       "3 -0.040756  0.818655  1.231301  1.584360 -2.103652  0.939735 -0.770357   \n",
       "4  0.716362  0.052499 -0.947138  1.301603 -0.710176 -0.206302  0.100330   \n",
       "\n",
       "          7         8         9  target  \n",
       "0 -2.902355 -1.032001  0.620666       0  \n",
       "1 -2.147366  0.918143 -0.925999       0  \n",
       "2  3.121716 -1.228138 -1.326703       0  \n",
       "3  1.072464 -0.521160  1.035603       1  \n",
       "4 -0.332693 -3.112213 -0.955480       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_toy_dataset():\n",
    "    ''' the characteristics of the dataset affect the degree to which we see this issue manifest\n",
    "        easily separable datasets with confidently correct models may not have the same issue as \n",
    "        noisier datasets with less confident models\n",
    "    '''\n",
    "    # Generating an unbalanced dataset\n",
    "    X, y = make_classification(\n",
    "        weights=[0.9,0.1], # Setting weights so classes are unbalanced\n",
    "        n_samples=100000,\n",
    "        n_features=10,\n",
    "        n_informative=3,\n",
    "        n_redundant=2,\n",
    "        n_classes=2,\n",
    "        class_sep=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    df = pd.DataFrame(X)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    df['target'] = y\n",
    "    return df\n",
    "\n",
    "generate_toy_dataset().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be68fe",
   "metadata": {},
   "source": [
    "# Experiment code\n",
    "\n",
    "This experiment trains and applies a random forest model both with and without resampling the training set.\n",
    "\n",
    "In each of the 2 experiments, a test set is first broken off and set aside to simulate \"production data\" that the model will be applied to in the future.\n",
    "\n",
    "For the \"resampling\" experiment, we use a downsampler.  If you like, you can try this with an upsampler as well.  This will take longer to run and tends to make the results slightly better and less variable but should not change the overall conclusion. \n",
    "\n",
    "For the \"non resampled\" experiment, we just feed the data in as-is without and modification.\n",
    "\n",
    "The experiment:\n",
    "    - resample the data (or not)\n",
    "    - break the data into train and validation sets\n",
    "    - train a model on the training set\n",
    "    - optimize a decision threshold using the validation set\n",
    "    - apply the model with this threshold to the \"production\" dataset\n",
    "    - evaluate the f1 statistic on the \"production\" dataset and compare to the results on the validation set\n",
    "    \n",
    "Do this twice, and compare the results (resampling vs not resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d360a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_threshold(probas, target):\n",
    "    ''' iterates over thresholds to choose the one with the highest f1 score '''\n",
    "    results = dict()\n",
    "    precision, recall, thresholds = precision_recall_curve(target, probas)\n",
    "    f1_scores = 2 * recall * precision / (recall + precision)\n",
    "    best_f1_ind = np.argmax(f1_scores)\n",
    "    results['best_threshold'] = thresholds[best_f1_ind]\n",
    "    results['validation_f1_score']  = np.max(f1_scores)\n",
    "    results['precision']      = precision[best_f1_ind]\n",
    "    results['recall']         = recall[best_f1_ind]\n",
    "    return results \n",
    "    \n",
    "def train_model_and_do_validation_predict(df_train, df_valid, target):\n",
    "    ''' trains the model and predicts on validation set\n",
    "        returns model and validation set predictions'''\n",
    "    X, y = df_train.drop(columns=target), df_train[target]\n",
    "    X_valid = df_valid.drop(columns=target)\n",
    "    model = RandomForestClassifier(n_jobs=-1, n_estimators=256, min_samples_leaf=20, random_state=42).fit(X, y)\n",
    "    return model, model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "def score_production_predictions(df_prod, target, model, threshold):\n",
    "    ''' computes the f1 score on the \"production\" dataset with the provided threshold '''\n",
    "    X_prod = df_prod.drop(columns=target)\n",
    "    P_prod = model.predict_proba(X_prod)[:, 1] > threshold\n",
    "    return f1_score(df_prod[target], P_prod)\n",
    "\n",
    "\n",
    "def train_optimize_and_predict_on_prod(train_val, df_prod, target):\n",
    "    ''' the full test, validate, tune threhsold, and predict on \"production data\" sequence '''\n",
    "    train, val = train_test_split(train_val, test_size=0.2, random_state=42)\n",
    "    model, P_val = train_model_and_do_validation_predict(train, val, target)\n",
    "    results = choose_best_threshold(P_val, val[target])\n",
    "    prod_f1_score = score_production_predictions(df_prod, target, model, results['best_threshold'])\n",
    "    results['prod_f1_score'] = prod_f1_score\n",
    "    return results\n",
    "\n",
    "def run_experiment(df, target):\n",
    "    # set aside test set for final evaluation\n",
    "    #     held out \"test set\" is called \"df_prod\" to denote that it's\n",
    "    #     our best representation of what the model will be encountering \"in prod\"\n",
    "    #     having the \"untouched\" class balance \n",
    "    train_val, df_prod = train_test_split(df, test_size=0.2, random_state=42) \n",
    "\n",
    "    # resampler - try different resamplers if you like\n",
    "    resampler = RandomUnderSampler(sampling_strategy=1.0, random_state=42) # 50/50 balanced undersampling\n",
    "    train_val_resampled, _ = resampler.fit_sample(train_val, train_val[target])\n",
    "        \n",
    "    # experiment 1: \n",
    "    #  - train model on resampled data\n",
    "    #  - pick optimal threshold based on validation set f1 score\n",
    "    #  - predict on \"production_data\" and compare to our expectations\n",
    "    #    as defined by validation set results\n",
    "    resampled_results = train_optimize_and_predict_on_prod(train_val_resampled, df_prod, target)\n",
    "    \n",
    "    # experiment 2: \n",
    "    #   - same as experiment 1 but do not resample the data first\n",
    "    raw_results = train_optimize_and_predict_on_prod(train_val, df_prod, target)\n",
    "    \n",
    "    results = pd.DataFrame([resampled_results, raw_results], index=['resampled', 'non-resampled']).T.round(2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651e271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resampled</th>\n",
       "      <th>non-resampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_f1_score</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prod_f1_score</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     resampled  non-resampled\n",
       "best_threshold            0.43           0.21\n",
       "validation_f1_score       0.79           0.50\n",
       "precision                 0.74           0.42\n",
       "recall                    0.84           0.60\n",
       "prod_f1_score             0.38           0.49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(df=generate_toy_dataset(), target='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4865f01",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Resampling:\n",
    "- estimated f1 = 79%\n",
    "- actual f1 = 38%\n",
    "\n",
    "No Resampling:\n",
    "- estimated f1 = 50%\n",
    "- actual f1 = 49%\n",
    "\n",
    "Using a resampled validation set inflated the apparent performance of the model (79% f1) while delivering a much lower performance on the actual dataset (38% f1).  This is one of the biggest risks in making this error - that the model will be deployed under the expectation of substantially greater performance than is actually attained on production data post-deployment.\n",
    "\n",
    "Compare this to the non-resampled dataset.  The actual performance on \"production data\" is much better (49% compared to 38%) and the estimated f1 based on the dataset is much closer to the production performance (50% on the validation set vs 49% on the production set).\n",
    "\n",
    "This is a common phenomenon when care isn't taken while using resampling.  This is only one of several related types of errors resampling can cause you to make if it is not implemented carefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3e5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
